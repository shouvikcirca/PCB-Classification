{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from keras import models, layers, optimizers\n",
    "import tensorflow as tf\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Model\n",
    "from Models.models import densenet\n",
    "model = densenet(121)\n",
    "model.compile(optimizer = optimizers.Adam(lr = 1e-3),loss = 'binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 679 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#Loading Validation Set\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "valid_datagen =  ImageDataGenerator(\n",
    "    rescale = 1/255.\n",
    ")\n",
    "\n",
    "valdir = 'Folds/3folds/fold1/Validation'\n",
    "valbatchsize = len(os.listdir(valdir+'/True')) + len(os.listdir(valdir+'/False'))\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valdir,\n",
    "    batch_size = valbatchsize,\n",
    "    class_mode = 'binary',\n",
    "    shuffle = True,\n",
    "    seed = 123\n",
    "\n",
    ")\n",
    "\n",
    "# valid_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_val_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfalsedirpath = 'Folds/3folds/fold1/Train/False'\n",
    "trainfalsedir = os.listdir(trainfalsedirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = np.zeros([2*len(trainfalsedir),600,600,3])\n",
    "ytrain = np.zeros(2*len(trainfalsedir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading False samples\n",
    "for i in range(len(trainfalsedir)):\n",
    "    xtrain[i] = img_to_array(load_img(trainfalsedirpath+'/'+trainfalsedir[i]))\n",
    "    ytrain[i] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintruedirpath = 'Folds/3folds/fold1/Train/True'\n",
    "traintruedir = os.listdir(traintruedirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading True samples\n",
    "start = len(trainfalsedir)\n",
    "for i in range(len(trainfalsedir), len(trainfalsedir)+len(traintruedir)):\n",
    "    xtrain[i] = img_to_array(load_img(traintruedirpath+'/'+traintruedir[i-start]))\n",
    "    ytrain[i] = 1.\n",
    "    \n",
    "xtrain = xtrain/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(training_epochs):\n",
    "    \n",
    "    #loading upsampled True samples\n",
    "    start = len(traintruedir)+len(trainfalsedir)\n",
    "    for i in range(len(trainfalsedir)+len(traintruedir),xtrain.shape[0]):\n",
    "        xtrain[i] = img_to_array(load_img(traintruedirpath+'/'+traintruedir[np.random.randint(len(traintruedir))]))/255.\n",
    "        ytrain[i] = 1.\n",
    "     \n",
    "        \n",
    "    model.fit(\n",
    "        x = xtrain,\n",
    "        y = ytrain,\n",
    "        epochs = 1,\n",
    "        batch_size = 34,\n",
    "        shuffle = True,\n",
    "        verbose = 0, \n",
    "    )\n",
    "    \n",
    "    val_loss, val_acc = model.evaluate(valid_generator, steps=1)\n",
    "    print('val_loss:{}\\tval_acc:{}'.format(val_loss, val_acc))\n",
    "    \n",
    "    f = 1\n",
    "    if val_loss < lowest_val_loss:\n",
    "        lowest_val_loss = val_loss\n",
    "        cpsavepath = 'upsampleddn121checkpoints/'+'fold_{}____'.format(f)+datetime.now().strftime(\"%d_%m_%Y____%H_%M_%S\")\n",
    "        with open(csavepath+'.json', \"w\") as json_file:\n",
    "            json_file.write(model.to_json())\n",
    "        model.save_weights(csavepath+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truedirpath = 'Folds/3folds/fold1/Train/True'\n",
    "truedir = os.listdir(truedirpath)\n",
    "truedir = np.array([int(i[:-4]) for i in truedir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "falsedirpath = 'Folds/3folds/fold1/Train/False'\n",
    "falsedir = os.listdir(falsedirpath)\n",
    "falsedir = np.array([int(i[:-4]) for i in falsedir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalcount = truedir.shape[0]+falsedir.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberofiterations = math.ceil((truedir.shape[0] + falsedir.shape[0])/bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.models import dn121scratch as dns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dns()\n",
    "model.compile(optimizer = optimizers.Adam(lr = 1e-3),loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
    "# my_callbacks = [\n",
    "#     tf.keras.callbacks.ModelCheckpoint(\n",
    "#         filepath='checkpoints2/'+'fold_{}____'.format(f)+datetime.now().strftime(\"%d_%m_%Y____%H_%M_%S\")+'.h5',\n",
    "#         monitor = 'val_loss',\n",
    "#         save_best_only = True\n",
    "#      ),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesleft = totalcount\n",
    "for i in range(numberofiterations):\n",
    "    \n",
    "    jcount = min(imagesleft, bs)\n",
    "    true_batchcount = round(truedir.shape[0]/(truedir.shape[0]+falsedir.shape[0])*jcount)\n",
    "    false_batchcount = jcount - true_batchcount\n",
    "    truebatch = np.zeros([true_batchcount,600,600,3])\n",
    "    falsebatch = np.zeros([false_batchcount,600,600,3])\n",
    "    trueims = truedir[i*true_batchcount:(i+1)*true_batchcount]\n",
    "    falseims = falsedir[i*false_batchcount:(i+1)*false_batchcount]\n",
    " \n",
    "#     print(trueims.shape[0], falseims.shape[0])\n",
    "   \n",
    "    for j in range(trueims.shape[0]):\n",
    "        truebatch[j] = img_to_array(load_img(truedirpath+'/'+str(trueims[j])+'.tif'))\n",
    "    \n",
    "    for j in range(falseims.shape[0]):\n",
    "        falsebatch[j] = img_to_array(load_img(falsedirpath+'/'+str(falseims[j])+'.tif'))\n",
    "        \n",
    "    batch = np.concatenate([truebatch, falsebatch], axis = 0)\n",
    "    y = np.concatenate([np.zeros([truebatch.shape[0]]), np.ones([falsebatch.shape[0]])], axis = 0)\n",
    "    \n",
    "    permindices = np.random.permutation(batch.shape[0])\n",
    "    batch = batch[permindices]\n",
    "    y = y[permindices].reshape(-1,1)\n",
    "    print(y.shape)\n",
    "    \n",
    "    del trueims;del falseims;del truebatch;del falsebatch\n",
    "    imagesleft-=bs\n",
    "    \n",
    "    model.fit(\n",
    "        x = batch,\n",
    "        y = y,\n",
    "        epochs = 1,\n",
    "        verbose = 2,\n",
    "    )\n",
    "    \n",
    "    del batch;del y;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import array_to_img\n",
    "plt.imshow(array_to_img(batch[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([7,14,21,28,35,49,56,63,70])\n",
    "b = np.random.permutation(9)\n",
    "a = a[b]\n",
    "\n",
    "print(b)\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
