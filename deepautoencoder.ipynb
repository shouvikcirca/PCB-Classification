{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from time import time\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "import tensorflow as tf\n",
    "import keras  \n",
    "from keras.applications import DenseNet121\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, NumpyArrayIterator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import models, layers, optimizers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import layers, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(600, 600, 3))\n",
    "\n",
    "print(input_img)\n",
    "x = layers.Conv2D(128, kernel_size = 3, strides = 1,  activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "print(x)\n",
    "x = layers.Conv2D(64, kernel_size = 3, strides = 1, activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "print(x)\n",
    "x = layers.Conv2D(32, kernel_size = 3, strides = 1, activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "print(encoded)\n",
    "\n",
    "x = layers.Conv2DTranspose(64, (3, 3), strides = 2, activation='relu', padding='same')(encoded)\n",
    "print(x)\n",
    "x = layers.Conv2DTranspose(128, (3, 3), strides = 2, activation='relu', padding='same')(x)\n",
    "print(x)\n",
    "decoded = layers.Conv2DTranspose(3, (3, 3), strides = 2, activation='relu', padding='same')(x)\n",
    "print(decoded)\n",
    "autoencoder = Model(input_img,decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading training data\n",
    "import os\n",
    "trainfalsedirpath = 'Folds/3folds/fold1/Train/False'\n",
    "trainfalsedir = os.listdir(trainfalsedirpath)\n",
    "\n",
    "\n",
    "xtrain = np.zeros([len(trainfalsedir),600,600,3])\n",
    "\n",
    "for k,v in enumerate(trainfalsedir):\n",
    "      xtrain[k] = img_to_array(load_img(trainfalsedirpath + '/' + v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numit = NumpyArrayIterator(\n",
    "    x = xtrain,\n",
    "    y = None,\n",
    "    image_data_generator = train_datagen,\n",
    "    batch_size = bs,\n",
    "    shuffle = True,\n",
    "    seed = 123,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading validation data\n",
    "valfalsedirpath = 'Folds/3folds/fold1/Validation/False'\n",
    "valfalsedir = os.listdir(valfalsedirpath)\n",
    "\n",
    "\n",
    "xval = np.zeros([len(valfalsedir),600,600,3])\n",
    "\n",
    "for k,v in enumerate(valfalsedir):\n",
    "      xval[k] = img_to_array(load_img(valfalsedirpath + '/' + v))/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "f = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.5\n",
    "lowest_val_loss = float('inf')\n",
    "epochs = 50\n",
    "\n",
    "seedarraypresent = 'seedarray.npy' in os.listdir()\n",
    "if seedarraypresent:\n",
    "    seedarray = np.load('seedarray.npy')\n",
    "else:\n",
    "    np.random.seed(123)\n",
    "    seedarray = np.random.randint(1000, size = epochs)\n",
    "    np.save('checkpointsandlogs/deepautoencoder/False_fold:{}_'.format(f) + 'seedarray.npy', seedarray)\n",
    "\n",
    "for i in range(50):\n",
    "    print('Epoch:{}'.format(i))\n",
    "    if 'numit' in dir():\n",
    "        del numit\n",
    "    \n",
    "    numit = NumpyArrayIterator(\n",
    "    x = xtrain,\n",
    "    y = None,\n",
    "    image_data_generator = train_datagen,\n",
    "    batch_size = bs,\n",
    "    shuffle = True,\n",
    "    seed = seedarray[i],   \n",
    "    )\n",
    "    \n",
    "    for samples in numit:\n",
    "        samples_noisy = samples.copy()\n",
    "        samples_noisy+=(noise_factor * np.random.normal(loc=0.0, scale=1.0, size = samples_noisy.shape))\n",
    "        autoencoder.fit(\n",
    "            samples_noisy,\n",
    "            samples,\n",
    "            batch_size = 34,\n",
    "            epochs = 1\n",
    "        )\n",
    "        del samples_noisy;\n",
    "        \n",
    "    xval_noisy = xval.copy()\n",
    "    xval_noisy+=(noise_factor * np.random.normal(loc=0.0, scale=1.0, size = xval_noisy.shape))\n",
    "    val_loss, val_acc = model.evaluate(xval_noisy, xval_noisy, xvalsteps=1)\n",
    "    del xval_noisy\n",
    "    \n",
    "    if val_loss < lowest_val_loss:\n",
    "        print('val_loss:{}'.format(val_loss))\n",
    "        lowest_val_loss = val_loss\n",
    "        cpsavepath = 'checkpointsandlogs/deepautoencoder/checkpoints/false_'+'fold_{}____'.format(f)+datetime.now().strftime(\"%d_%m_%Y____%H_%M_%S\")\n",
    "        with open(csavepath+'.json', \"w\") as json_file:\n",
    "            json_file.write(model.to_json())\n",
    "        model.save_weights(csavepath+'.h5')\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = autoencoder.predict(np.expand_dims(img_to_array(load_img(trainfalsedirpath + '/' + trainfalsedir[21])), axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend\n",
    "backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
